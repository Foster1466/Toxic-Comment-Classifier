# Toxic-Comment-Classifier

## Abstract
People express themselves freely and without reluctance at online platforms only when they feel comfortable. Any threat of abuse or harassment will make them leave the conversation and prohibit them from participating in any good conversation in future. It is hence a vital requirement for any organization or community to have an automated system which can identify such toxic comments and report/block the same immediately. This problem falls under the category of Natural Language Processing where we try to identify the intention of the speaker, and act accordingly. Research on modelling a solution to this problem has already begun. We personally feel it is important to handle any such nuisance and create a more user-friendly experience regarding online conversation for each one of us. Only then will people enjoy participating in discussions. The idea of our project and the dataset has been taken from kaggle. Under the name of toxic comment classification challenge, it aims to identify and classify online toxic comments. It is being conducted as research by the Conversation AI team, which is an initiative by Jigsaw and Google.